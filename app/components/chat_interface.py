import streamlit as st
from openai import OpenAI
import base64
import os

def get_task_prompt(task_type, text):
    """æ ¹æ®ä»»åŠ¡ç±»å‹ç”Ÿæˆæç¤ºè¯"""
    prompts = {
        "è§£é‡Š": f"è¯·è§£é‡Šä»¥ä¸‹å†…å®¹ï¼š\n\n{text}",
        "æ€»ç»“": f"è¯·æ€»ç»“ä»¥ä¸‹å†…å®¹ï¼š\n\n{text}",
        "æ”¹å†™": f"è¯·å°†ä»¥ä¸‹å†…å®¹æ”¹å†™ä¸ºæ›´æ¸…æ™°çš„è¡¨è¾¾ï¼š\n\n{text}"
    }
    return prompts.get(task_type, prompts["è§£é‡Š"])

def process_selected_text(text, task_type):
    """å¤„ç†é€‰ä¸­çš„æ–‡æœ¬"""
    try:
        client = OpenAI(
            api_key=os.getenv("OPENAI_API_KEY", "sk-lxUWT88Z2f--5a-7CKZjxQ"),
            base_url=os.getenv("OPENAI_BASE_URL", "https://api.ai.it.cornell.edu")
        )
        
        prompt = get_task_prompt(task_type, text)
        
        response = client.chat.completions.create(
            model="openai.gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡æ¡£åˆ†æåŠ©æ‰‹ï¼Œè¯·æ ¹æ®ç”¨æˆ·çš„è¦æ±‚å¤„ç†æ–‡æœ¬å†…å®¹ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=500
        )
        return response.choices[0].message.content
    except Exception as e:
        st.error(f"å¤„ç†æ–‡æœ¬æ—¶å‡ºé”™ï¼š{str(e)}")
        return None

def handle_task_button(task_type):
    """å¤„ç†ä»»åŠ¡æŒ‰é’®ç‚¹å‡»"""
    selected_text = st.session_state.get("selected_text", "")

    if not isinstance(selected_text, str) or selected_text.strip() == "":
        st.warning("è¯·å…ˆé€‰æ‹©è¦å¤„ç†çš„æ–‡æœ¬")
        return

    # æ ¹æ®ä»»åŠ¡ç±»å‹å¤„ç†æ–‡æœ¬
    if task_type == "explain":
        prompt = f"è¯·è§£é‡Šä»¥ä¸‹æ–‡æœ¬çš„å«ä¹‰ï¼š\n\n{selected_text}"
    elif task_type == "summarize":
        prompt = f"è¯·æ€»ç»“ä»¥ä¸‹æ–‡æœ¬çš„ä¸»è¦å†…å®¹ï¼š\n\n{selected_text}"
    elif task_type == "rewrite":
        prompt = f"è¯·ç”¨æ›´ç®€æ´çš„è¯­è¨€é‡å†™ä»¥ä¸‹æ–‡æœ¬ï¼š\n\n{selected_text}"
    else:
        st.error("æœªçŸ¥çš„ä»»åŠ¡ç±»å‹")
        return

    # è°ƒç”¨ OpenAI API
    try:
        client = OpenAI(
            api_key=os.getenv("OPENAI_API_KEY", "sk-lxUWT88Z2f--5a-7CKZjxQ"),
            base_url=os.getenv("OPENAI_BASE_URL", "https://api.ai.it.cornell.edu")
        )
        
        response = client.chat.completions.create(
            model="openai.gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡æœ¬åˆ†æåŠ©æ‰‹ï¼Œè¯·ç”¨ç®€æ´æ˜äº†çš„è¯­è¨€å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=500
        )
        
        # è·å–å›å¤å†…å®¹
        reply = response.choices[0].message.content
        
        # æ›´æ–°èŠå¤©å†å²
        st.session_state.chat_history.append({
            "role": "user",
            "content": f"ã€{task_type}ã€‘{selected_text}"
        })
        st.session_state.chat_history.append({
            "role": "assistant",
            "content": reply
        })
        
        # æ¸…ç©ºé€‰ä¸­çš„æ–‡æœ¬
        st.session_state["selected_text"] = None
        
        # åˆ·æ–°é¡µé¢
        st.rerun()
        
    except Exception as e:
        st.error(f"å¤„ç†æ–‡æœ¬æ—¶å‡ºé”™ï¼š{str(e)}")
        return None

def get_pdf_summary(pdf_content):
    """è·å– PDF æ‘˜è¦"""
    try:
        client = OpenAI(
            api_key=os.getenv("OPENAI_API_KEY", "sk-lxUWT88Z2f--5a-7CKZjxQ"),
            base_url=os.getenv("OPENAI_BASE_URL", "https://api.ai.it.cornell.edu")
        )
        
        prompt = f"""è¯·å¯¹ä»¥ä¸‹æ–‡æ¡£å†…å®¹è¿›è¡Œç®€è¦æ€»ç»“ï¼ŒåŒ…æ‹¬ï¼š
1. æ–‡æ¡£çš„ä¸»è¦ä¸»é¢˜
2. å…³é”®è¦ç‚¹
3. é‡è¦ç»“è®º

æ–‡æ¡£å†…å®¹ï¼š
{pdf_content}
"""
        
        response = client.chat.completions.create(
            model="openai.gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡æ¡£åˆ†æåŠ©æ‰‹ï¼Œè¯·ç”¨ç®€æ´æ˜äº†çš„è¯­è¨€æ€»ç»“æ–‡æ¡£å†…å®¹ã€‚"},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=500
        )
        return response.choices[0].message.content
    except Exception as e:
        st.error(f"ç”Ÿæˆæ‘˜è¦æ—¶å‡ºé”™ï¼š{str(e)}")
        return None

def render_pdf_summary():
    """æ¸²æŸ“ PDF æ‘˜è¦éƒ¨åˆ†"""
    st.markdown("### ğŸ“‘ æ–‡æ¡£æ‘˜è¦")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰ PDF å†…å®¹
    if st.session_state.get("current_file"):
        # å¦‚æœæœ‰ PDF å†…å®¹ï¼Œæ˜¾ç¤ºæ‘˜è¦
        if "pdf_summary" not in st.session_state and "pdf_text" in st.session_state:
            with st.spinner("æ­£åœ¨ç”Ÿæˆæ–‡æ¡£æ‘˜è¦..."):
                summary = get_pdf_summary(st.session_state["pdf_text"])
                if summary:
                    st.session_state["pdf_summary"] = summary
        
        # æ˜¾ç¤ºæ‘˜è¦å†…å®¹
        if "pdf_summary" in st.session_state:
            st.markdown(st.session_state["pdf_summary"])
    else:
        # å¦‚æœæ²¡æœ‰ PDFï¼Œæ˜¾ç¤ºå ä½å†…å®¹
        st.info("è¯·ä¸Šä¼  PDF æ–‡æ¡£ä»¥æŸ¥çœ‹æ‘˜è¦")

def render_chat_interface():
    """æ¸²æŸ“èŠå¤©ç•Œé¢"""
    # æ˜¾ç¤º PDF æ‘˜è¦
    render_pdf_summary()
    
    st.markdown("---")
    
    # åˆå§‹åŒ–èŠå¤©å†å²
    if "chat_history" not in st.session_state:
        st.session_state["chat_history"] = []
    
    # æ˜¾ç¤ºèŠå¤©å†å²
    for message in st.session_state["chat_history"]:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
    
    # æ·»åŠ ç¬”è®°å¯¼å‡ºæŒ‰é’®
    if st.button("ğŸ“’ å¯¼å‡ºç¬”è®°", key="export_notes_btn"):
        handle_export_notes()
    
    # ç”¨æˆ·è¾“å…¥åŒºåŸŸ
    if prompt := st.chat_input("è¾“å…¥æ‚¨çš„é—®é¢˜..."):
        if "chat_history" not in st.session_state:
            st.session_state.chat_history = []
        
        # æ·»åŠ ç”¨æˆ·é—®é¢˜åˆ°èŠå¤©å†å²
        st.session_state.chat_history.append({
            "role": "user",
            "content": prompt
        })
        
        # å¤„ç†ç”¨æˆ·é—®é¢˜
        response = process_selected_text(prompt, "explain")
        if response:
            # æ·»åŠ åŠ©æ‰‹å›å¤åˆ°èŠå¤©å†å²
            st.session_state.chat_history.append({
                "role": "assistant",
                "content": response
            })
            
            # ä½¿ç”¨ st.rerun() é‡æ–°åŠ è½½é¡µé¢
            st.rerun()

def handle_export_notes():
    """å¤„ç†ç¬”è®°å¯¼å‡ºåŠŸèƒ½"""
    try:
        # æ£€æŸ¥æ˜¯å¦æœ‰èŠå¤©å†å²
        if not st.session_state.get("chat_history"):
            st.warning("æ²¡æœ‰å¯ç”¨çš„èŠå¤©è®°å½•æ¥ç”Ÿæˆç¬”è®°")
            return
            
        # æ„å»ºæç¤ºè¯
        prompt = "è¯·æ ¹æ®ä»¥ä¸‹å¯¹è¯å†…å®¹æ•´ç†å‡ºä¸€ä»½ç»“æ„åŒ–ã€æ¡ç†æ¸…æ™°çš„é˜…è¯»ç¬”è®°ï¼š\n\n"
        for message in st.session_state["chat_history"]:
            role = "ç”¨æˆ·" if message["role"] == "user" else "AIåŠ©æ‰‹"
            prompt += f"{role}: {message['content']}\n\n"
        
        # åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯
        client = OpenAI(
            api_key=os.getenv("OPENAI_API_KEY", "sk-lxUWT88Z2f--5a-7CKZjxQ"),
            base_url=os.getenv("OPENAI_BASE_URL", "https://api.ai.it.cornell.edu")
        )
        
        # è°ƒç”¨ OpenAI API ç”Ÿæˆç¬”è®°
        with st.spinner("æ­£åœ¨ç”Ÿæˆç¬”è®°..."):
            response = client.chat.completions.create(
                model="openai.gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¬”è®°æ•´ç†åŠ©æ‰‹ï¼Œè¯·æ ¹æ®å¯¹è¯å†…å®¹ç”Ÿæˆç»“æ„åŒ–çš„é˜…è¯»ç¬”è®°ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7
            )
            
            notes = response.choices[0].message.content
            
            # ä¿å­˜ç¬”è®°å†…å®¹å¹¶åˆ‡æ¢åˆ°ç¬”è®°é—®ç­”ç•Œé¢
            st.session_state["notes_content"] = notes
            st.session_state["has_notes"] = True  # è®¾ç½®ç¬”è®°çŠ¶æ€
            st.session_state["current_page"] = "notes_chat"
            st.rerun()
                    
    except Exception as e:
        st.error(f"ç”Ÿæˆç¬”è®°æ—¶å‡ºé”™: {str(e)}")
        return None

def render_notes_chat_interface():
    """æ¸²æŸ“åŸºäºç¬”è®°çš„èŠå¤©ç•Œé¢"""
    st.subheader("ğŸ“˜ æ ¹æ®ç¬”è®°ç»§ç»­æé—®")
    
    # åˆå§‹åŒ–ç¬”è®°èŠå¤©å†å²
    if "notes_chat_history" not in st.session_state:
        st.session_state["notes_chat_history"] = []
    
    # æ˜¾ç¤ºèŠå¤©å†å²
    for message in st.session_state["notes_chat_history"]:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
    
    # ç”¨æˆ·è¾“å…¥åŒºåŸŸ
    if prompt := st.chat_input("è¾“å…¥æ‚¨çš„é—®é¢˜..."):
        # æ·»åŠ ç”¨æˆ·é—®é¢˜åˆ°èŠå¤©å†å²
        st.session_state["notes_chat_history"].append({
            "role": "user",
            "content": prompt
        })
        
        # æ„å»ºç³»ç»Ÿæç¤ºè¯ï¼ŒåŒ…å«ç¬”è®°å†…å®¹
        system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å­¦ä¹ åŠ©æ‰‹ã€‚è¯·åŸºäºä»¥ä¸‹ç¬”è®°å†…å®¹å›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼š

{st.session_state.get("notes_content", "")}

è¯·ç¡®ä¿ä½ çš„å›ç­”ï¼š
1. å‡†ç¡®åæ˜ ç¬”è®°å†…å®¹
2. æ¸…æ™°æ˜“æ‡‚
3. å¦‚æœé—®é¢˜è¶…å‡ºç¬”è®°èŒƒå›´ï¼Œè¯·æ˜ç¡®è¯´æ˜
"""
        
        try:
            client = OpenAI(
                api_key=os.getenv("OPENAI_API_KEY", "sk-lxUWT88Z2f--5a-7CKZjxQ"),
                base_url=os.getenv("OPENAI_BASE_URL", "https://api.ai.it.cornell.edu")
            )
            
            response = client.chat.completions.create(
                model="openai.gpt-4o-mini",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7
            )
            
            # æ·»åŠ åŠ©æ‰‹å›å¤åˆ°èŠå¤©å†å²
            st.session_state["notes_chat_history"].append({
                "role": "assistant",
                "content": response.choices[0].message.content
            })
            
            # åˆ·æ–°é¡µé¢
            st.rerun()
            
        except Exception as e:
            st.error(f"å¤„ç†é—®é¢˜æ—¶å‡ºé”™: {str(e)}")
            return None

# ... existing code ... 